[[apim-kubernetes-operator-architecture]]
= GKO Architecture
:page-sidebar: apim_3_x_sidebar
:page-permalink: apim/3.x/apim_kubernetes_operator_architecture.html
:page-folder: apim/kubernetes
:page-layout: apim3x

== About Gravitee Kubernetes Operators

A link:https://kubernetes.io/docs/concepts/extend-kubernetes/operator/[Kubernetes operator^] is a method of packaging, deploying, and managing a Kubernetes application. A Kubernetes application is both deployed on Kubernetes and managed using the Kubernetes API and `kubectl` tooling.

In this context, a Kubernetes operator is an application-specific controller that extends the functionality of the Kubernetes API to create, configure, and manage application instances.

== Architecture overview

The current functionality of the Gravitee Kubernetes Operator (GKO) allows for three main deployment scenarios, as described below.

NOTE: To learn how to deploy GKO on a production cluster, see the link:{{ '/apim/3.x/apim_kubernetes_operator_installation_cluster.html' | relative_url }}[production deployment] section.

=== Standard deployment

In the standard deployment scenario, the Management API and the API Gateway are deployed in the same Kubernetes cluster.

With this workflow, the GKO listens for link:{{ '/apim/3.x/apim_kubernetes_operator_definitions.html' | relative_url }}[Custom Resource Definitions (CRDs] and for each custom resource, a link:https://kubernetes.io/docs/concepts/configuration/configmap/[ConfigMap^] is created and the API is pushed to the Management API using the import endpoint.

The API Gateway uses the link:https://github.com/gravitee-io/gravitee-kubernetes/tree/master/gravitee-kubernetes-client[Kubernetes Client^] to listen for `ConfigMap`s (with a custom label), and deploys the APIs accordingly.

The following diagram illustrates the standard deployment architectural approach:

image:{% link /images/apim/3.x/kubernetes/gko-architecture-1-standard.png %}[]

=== Deployment on multiple clusters

In this scenario, the assimption is that both of the following requirements should be met:

1. The user manages multiple Kubernetes clusters with a different set of APIs for each cluster.
2. All APIs are managed using a single API Console.

To make this work with GKO, it should be installed on all the required clusters.

The following diagram illustrates the multi-cluster deployment architectural approach:

image:{% link /images/apim/3.x/kubernetes/gko-architecture-2-multi-cluster.png %}[]

=== Deployment on multiple environments

In this scenario, a single GKO is deployed that can publish APIs to different environments (logical or physical). This is managed directly from the link:{{ '/apim/3.x/apim_kubernetes_operator_user_guide_api_definition.html' | relative_url }}[API Definition] custom resource, which refers a link:{{ '/apim/3.x/apim_kubernetes_operator_user_guide_management_context.html' | relative_url }}[Management Context] custom resource.

The following diagram illustrates the multi-environment deployment architectural approach:

image:{% link /images/apim/3.x/kubernetes/gko-architecture-3-multi-env.png %}[]
